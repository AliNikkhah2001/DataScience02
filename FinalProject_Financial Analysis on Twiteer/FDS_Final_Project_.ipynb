{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0dcf78d-0328-49c2-b500-eb079b9d7ccc"
      },
      "source": [
        "<h1 style=\"text-align: center\">\n",
        "Foundations of DataScience </br>\n",
        "</h1>\n",
        "<h2 style=\"text-align: center\">\n",
        "Course Project </br>\n",
        "Financial Analysis on Twitter\n",
        "</h2>\n",
        "\n"
      ],
      "id": "a0dcf78d-0328-49c2-b500-eb079b9d7ccc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e138d7fe-d8ee-4a1e-8468-48bfec905ff2"
      },
      "source": [
        "\n",
        "  <style>\n",
        "    table {\n",
        "      width: 100%;\n",
        "      border-collapse: collapse;\n",
        "    }\n",
        "\n",
        "    th, td {\n",
        "      border: 1px solid #dddddd;\n",
        "      text-align: left;\n",
        "      padding: 8px;\n",
        "    }\n",
        "\n",
        "    th {\n",
        "      background-color: #f2f2f2;\n",
        "    }\n",
        "\n",
        "    .box {\n",
        "      border: 1px solid #000;\n",
        "      padding: 10px;\n",
        "      width: 400px; /* Adjust the width as needed */\n",
        "      margin: 20px auto;\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"box\">\n",
        "  <table>\n",
        "    <tr>\n",
        "      <th colspan=\"2\">Personal Info</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>First Name:</td>\n",
        "      <td>Ali</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Last Name:</td>\n",
        "      <td>Nikkhah</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Student Number:</td>\n",
        "      <td>99102445</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>Git:</td>\n",
        "      <td><a href=\"https://github.com/AliNikkhah2001/DataScience02\" target=\"_blank\">https://github.com/AliNikkhah2001/DataScience02</a></td>\n",
        "    </tr>\n",
        "  </table>\n",
        "</div>\n",
        "\n"
      ],
      "id": "e138d7fe-d8ee-4a1e-8468-48bfec905ff2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTlyUyiY3L_5"
      },
      "source": [
        "<!DOCTYPE html>\n",
        "\n",
        "<body>\n",
        "\n",
        "<h2>Phase I</h2>\n",
        "\n",
        "<table border=\"1\">\n",
        "  <tr>\n",
        "    <th>Task</th>\n",
        "    <th>Description</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Load dataset and preprocess</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>2</td>\n",
        "    <td>Express information of least and most tweeted stocks by segmentation over companies based on tweets related to them</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>3</td>\n",
        "    <td>Distribution of 5 stocks over time</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>4</td>\n",
        "    <td>Distribution of all financial tweets over time</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5</td>\n",
        "    <td>Distribution of retweets per tweets that company mentioned on</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>6</td>\n",
        "    <td>Most information of 2 stocks computed solely from financial dataset</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>7</td>\n",
        "    <td>Movement directions of two stocks compared to real-world news</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>8</td>\n",
        "    <td>Co-occurrence of stocks over tweets</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "id": "yTlyUyiY3L_5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e15a02d2-fdf4-41a0-9ba1-b35aff9588c5"
      },
      "source": [
        "* Libraries installation and initialization"
      ],
      "id": "e15a02d2-fdf4-41a0-9ba1-b35aff9588c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oWIpPcW9At71"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade pip"
      ],
      "id": "oWIpPcW9At71"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4upTMuIcAvsx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install necessary libraries\n",
        "!pip install tensorflow-data-validation"
      ],
      "id": "4upTMuIcAvsx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2xVYjK9MI23c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import os\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import tensorflow_data_validation as tfdv\n",
        "from tensorflow_data_validation.utils import display_util\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n"
      ],
      "id": "2xVYjK9MI23c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7f30e54-8656-4cd1-98fa-1f31b9ea4a54"
      },
      "source": [
        "* Load dataset"
      ],
      "id": "a7f30e54-8656-4cd1-98fa-1f31b9ea4a54"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc799865-83a5-47f6-9992-43d0f4269c64",
        "outputId": "a4648b81-e80c-4483-e44f-f7f99dbe7968"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading and extracting datasets: 100%|██████████| 4/4 [01:04<00:00, 16.01s/it]\n"
          ]
        }
      ],
      "source": [
        "# Create a folder for the dataset if it doesn't exist\n",
        "dataset_folder = 'dataset/P1'\n",
        "os.makedirs(dataset_folder, exist_ok=True)\n",
        "\n",
        "# List of dataset URLs\n",
        "dataset_urls = [\n",
        "    'https://zenodo.org/records/2686862/files/companies.csv.zip?download=1',\n",
        "    'https://zenodo.org/records/2686862/files/entities.csv.zip?download=1',\n",
        "    'https://zenodo.org/records/2686862/files/tweets.csv.zip?download=1',\n",
        "    'https://zenodo.org/records/2686862/files/users.csv.zip?download=1'\n",
        "]\n",
        "\n",
        "# Download and extract each dataset with tqdm progress bar\n",
        "for url in tqdm(dataset_urls, desc=\"Downloading and extracting datasets\"):\n",
        "    file_name = url.split('/')[-1].split('?')[0]\n",
        "    zip_file_path = os.path.join(dataset_folder, file_name)\n",
        "    csv_file_path = os.path.join(dataset_folder, file_name.replace('.zip', ''))\n",
        "\n",
        "    # Download the zip file\n",
        "    urllib.request.urlretrieve(url, zip_file_path)\n",
        "\n",
        "    # Extract the contents of the zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(csv_file_path)\n",
        "\n",
        "    # Remove the zip file after extraction\n",
        "    os.remove(zip_file_path)\n"
      ],
      "id": "cc799865-83a5-47f6-9992-43d0f4269c64"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZK55FnwA-0N",
        "outputId": "95346a24-10e5-474c-d235-0dc0ae6f8b62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading Datasets: 100%|██████████| 3/3 [01:03<00:00, 21.06s/file]\n"
          ]
        }
      ],
      "source": [
        "dataset_files = ['companies.csv/companies', 'entities.csv/entities', 'tweets.csv/tweets']\n",
        "\n",
        "# Create a list to store the DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Use tqdm to show progress bar while loading datasets\n",
        "for file in tqdm(dataset_files, desc=\"Loading Datasets\", unit=\"file\"):\n",
        "    file_path = os.path.join(dataset_folder, file + '.csv')\n",
        "    df = pd.read_csv(file_path)\n",
        "    dataframes.append(df)\n",
        "\n",
        "# Unpack the DataFrames\n",
        "companies_df, entities_df, tweets_df = dataframes"
      ],
      "id": "hZK55FnwA-0N"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1eyOv8LCg-y"
      },
      "source": [
        "**We face several erros on parsing users dataframe. in the comming cells of the notebook, we try to solve this problem**"
      ],
      "id": "N1eyOv8LCg-y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ChmgIQn9C02I"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Load 'users.csv' into a pandas DataFrame, skipping lines with extra fields\n",
        "users_df_path = os.path.join(dataset_folder, 'users.csv/users.csv')\n",
        "users_df = pd.read_csv(users_df_path, error_bad_lines=False)"
      ],
      "id": "ChmgIQn9C02I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAhhsEYLDR-X",
        "outputId": "687eb9f0-3e23-42f9-cc38-f9bf52378698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Information about the Users DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 597411 entries, 0 to 597410\n",
            "Data columns (total 16 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   id                597411 non-null  int64  \n",
            " 1   name              593020 non-null  object \n",
            " 2   screen_name       597411 non-null  object \n",
            " 3   statuses_count    597411 non-null  int64  \n",
            " 4   followers_count   597411 non-null  int64  \n",
            " 5   friends_count     597411 non-null  int64  \n",
            " 6   favourites_count  597411 non-null  int64  \n",
            " 7   listed_count      597407 non-null  object \n",
            " 8   url               150160 non-null  object \n",
            " 9   lang              597407 non-null  object \n",
            " 10  time_zone         243540 non-null  object \n",
            " 11  location          333734 non-null  object \n",
            " 12  verified          4591 non-null    object \n",
            " 13  description       409968 non-null  object \n",
            " 14  created_at        597405 non-null  object \n",
            " 15  bot               25988 non-null   float64\n",
            "dtypes: float64(1), int64(5), object(10)\n",
            "memory usage: 72.9+ MB\n",
            "None\n",
            "\n",
            "Information about the Companies DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30032 entries, 0 to 30031\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   ticker          30032 non-null  object \n",
            " 1   name            30032 non-null  object \n",
            " 2   exchange        30032 non-null  object \n",
            " 3   capitalization  22617 non-null  float64\n",
            "dtypes: float64(1), object(3)\n",
            "memory usage: 938.6+ KB\n",
            "None\n",
            "\n",
            "Information about the Entities DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 36482461 entries, 0 to 36482460\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Dtype \n",
            "---  ------       ----- \n",
            " 0   tweet_id     int64 \n",
            " 1   entity_type  object\n",
            " 2   text         object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 835.0+ MB\n",
            "None\n",
            "\n",
            "Information about the Tweets DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9091539 entries, 0 to 9091538\n",
            "Data columns (total 10 columns):\n",
            " #   Column                 Dtype \n",
            "---  ------                 ----- \n",
            " 0   id                     int64 \n",
            " 1   text                   object\n",
            " 2   user_id                int64 \n",
            " 3   in_reply_to_status_id  int64 \n",
            " 4   in_reply_to_user_id    int64 \n",
            " 5   retweeted_status_id    int64 \n",
            " 6   retweeted_user_id      int64 \n",
            " 7   lang                   object\n",
            " 8   source                 object\n",
            " 9   created_at             object\n",
            "dtypes: int64(6), object(4)\n",
            "memory usage: 693.6+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nInformation about the Users DataFrame:\")\n",
        "print(users_df.info())\n",
        "\n",
        "print(\"\\nInformation about the Companies DataFrame:\")\n",
        "print(companies_df.info())\n",
        "\n",
        "print(\"\\nInformation about the Entities DataFrame:\")\n",
        "print(entities_df.info())\n",
        "\n",
        "print(\"\\nInformation about the Tweets DataFrame:\")\n",
        "print(tweets_df.info())"
      ],
      "id": "QAhhsEYLDR-X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAsTBMwqHVXD",
        "outputId": "5ce3fdff-1870-45c0-bd27-52f7b5c0abe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of zero columns deleted: 0\n",
            "Number of zero rows deleted: 0\n",
            "Number of zero columns deleted: 0\n",
            "Number of zero rows deleted: 0\n",
            "Number of zero columns deleted: 0\n",
            "Number of zero rows deleted: 0\n",
            "Number of zero columns deleted: 0\n",
            "Number of zero rows deleted: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def remove_zero_columns_rows(df):\n",
        "    # Remove zero columns\n",
        "    zero_columns_before = df.shape[1]\n",
        "    df = df.loc[:, (df != 0).any(axis=0)]\n",
        "    zero_columns_after = df.shape[1]\n",
        "\n",
        "    # Remove zero rows\n",
        "    zero_rows_before = df.shape[0]\n",
        "    df = df.loc[(df != 0).any(axis=1)]\n",
        "    zero_rows_after = df.shape[0]\n",
        "\n",
        "    # Print the number of zero rows and columns deleted\n",
        "    print(f\"Number of zero columns deleted: {zero_columns_before - zero_columns_after}\")\n",
        "    print(f\"Number of zero rows deleted: {zero_rows_before - zero_rows_after}\")\n",
        "\n",
        "    return df\n",
        "users_df = remove_zero_columns_rows(users_df)\n",
        "companies_df = remove_zero_columns_rows(companies_df)\n",
        "entities_df = remove_zero_columns_rows(entities_df)\n",
        "tweets_df = remove_zero_columns_rows(tweets_df)\n"
      ],
      "id": "UAsTBMwqHVXD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro7yAjr2Ip9s",
        "outputId": "124badc7-c98b-4da4-a6b5-9f47f61bd088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicated rows removed: 0\n",
            "Number of duplicated rows removed: 0\n",
            "Number of duplicated rows removed: 0\n",
            "Number of duplicated rows removed: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def remove_duplicates(df):\n",
        "    # Count the number of duplicated rows before removal\n",
        "    duplicates_before = df.duplicated().sum()\n",
        "\n",
        "    # Remove duplicated rows\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    # Count the number of duplicated rows after removal\n",
        "    duplicates_after = df.duplicated().sum()\n",
        "\n",
        "    # Print the number of removed duplicate rows\n",
        "    print(f\"Number of duplicated rows removed: {duplicates_before - duplicates_after}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the function to each DataFrame with tqdm progress bar\n",
        "users_df = remove_duplicates(users_df)\n",
        "companies_df = remove_duplicates(companies_df)\n",
        "entities_df = remove_duplicates(entities_df)\n",
        "tweets_df = remove_duplicates(tweets_df)\n"
      ],
      "id": "ro7yAjr2Ip9s"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2AZufsEKQ_R"
      },
      "source": [
        " * Statistics on most and least tweeted stocks. Perform segmentation of the companies based on the number of tweets they have. Provide relevant visualizations."
      ],
      "id": "w2AZufsEKQ_R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWPHSV1rPXCF",
        "outputId": "86d8a811-1c65-4671-f178-149398a5f40b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Companies DataFrame:\n",
            "ticker                 name exchange  capitalization\n",
            "  BMTC Bryn Mawr Bank Corp.   NASDAQ     730480000.0\n",
            "\n",
            "Tweets DataFrame:\n",
            "                id                                                                                                    text            user_id  in_reply_to_status_id  in_reply_to_user_id  retweeted_status_id  retweeted_user_id lang                                                        source                     created_at\n",
            "866962922362126336 https://t.co/KA6yh5M9go Trading Expert Jason Bond has a Special Offer Just for You! $COP $VLO $APC $APA 726445144812081154                      0                    0                    0                  0   en <a href=\"https://www.smqueue.com/\" rel=\"nofollow\">smqueue</a> Tue May 23 10:24:02 +0000 2017\n",
            "\n",
            "Entities DataFrame:\n",
            "          tweet_id entity_type           text\n",
            "895697443098165248     mention NEO_Blockchain\n"
          ]
        }
      ],
      "source": [
        "print(\"Companies DataFrame:\")\n",
        "random_company_sample = companies_df.sample(n=1)\n",
        "print(random_company_sample.to_string(index=False))\n",
        "\n",
        "# Print one random sample from tweets_df\n",
        "print(\"\\nTweets DataFrame:\")\n",
        "random_tweet_sample = tweets_df.sample(n=1)\n",
        "print(random_tweet_sample.to_string(index=False))\n",
        "\n",
        "# Print one random sample from entities_df\n",
        "print(\"\\nEntities DataFrame:\")\n",
        "random_entity_sample = entities_df.sample(n=1)\n",
        "print(random_entity_sample.to_string(index=False))"
      ],
      "id": "CWPHSV1rPXCF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ssOWVmxEPkxk"
      },
      "outputs": [],
      "source": [
        "companies_tickers = companies_df['ticker'].to_list()"
      ],
      "id": "ssOWVmxEPkxk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAmVH1kUQyjr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming tweets_df is the DataFrame containing the tweets and companies_df is the DataFrame containing companies information\n",
        "\n",
        "# Create a new column 'tickers_list' in the Tweets DataFrame to store the found tickers\n",
        "tweets_df['tickers_list'] = np.nan\n",
        "\n",
        "# Create an empty list to store found tickers for each row\n",
        "found_tickers_list = []\n",
        "\n",
        "# Loop through each row in the tweets DataFrame and search for company tickers\n",
        "for index, row in tweets_df.iterrows():\n",
        "    tweet_text = row['text']\n",
        "    found_tickers = []\n",
        "\n",
        "    # Loop through each ticker in the Companies DataFrame\n",
        "    for company_ticker in companies_df['ticker']:\n",
        "        # Check if the ticker exists in the tweet text\n",
        "        if str(company_ticker) in str(tweet_text):\n",
        "            found_tickers.append(company_ticker)\n",
        "\n",
        "    # Append the list of found tickers for this row to the overall list\n",
        "    found_tickers_list.append(found_tickers)\n",
        "\n",
        "# Assign the list of found tickers to the 'tickers_list' column in the Tweets DataFrame\n",
        "tweets_df['tickers_list'] = found_tickers_list\n",
        "\n",
        "# Display the modified Tweets DataFrame with the 'tickers_list' column\n",
        "print(tweets_df.head())\n"
      ],
      "id": "ZAmVH1kUQyjr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcBVP9eyPc1Q",
        "outputId": "a95edffc-c7f1-49ac-96de-49906938826f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30032\n"
          ]
        }
      ],
      "source": [
        "print(len(companies_tickers))"
      ],
      "id": "HcBVP9eyPc1Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_O2ktUaOxvP",
        "outputId": "2c544446-dbb8-4576-ba65-88f21464f3b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         id  \\\n",
            "0        865326129644797957   \n",
            "1        865326133008642049   \n",
            "2        865326134262681600   \n",
            "3        865326134917050368   \n",
            "4        865326135952855040   \n",
            "...                     ...   \n",
            "9091534  907725480618610689   \n",
            "9091535  907725484909309957   \n",
            "9091536  907725487996272640   \n",
            "9091537  907725490760376320   \n",
            "9091538  907725492874223616   \n",
            "\n",
            "                                                      text  \\\n",
            "0        RT @cruzfloresiv: To all the weak hands who so...   \n",
            "1        Investors Eye Fed, But Bond ETFs Still Add Ass...   \n",
            "2        Sell $NLNK (Ne❑wLink Genetics Corporation) tha...   \n",
            "3        Increase: $VCO $NTES $BPT $ENIC $QIWI $JP $STX...   \n",
            "4        Former #FDA commissioner Califf joins Verily, ...   \n",
            "...                                                    ...   \n",
            "9091534  Contrasting Pure Cycle Corporation $PCYO &amp;...   \n",
            "9091535  Contrasting Harvard Bioscience $HBIO &amp; Ful...   \n",
            "9091536  NRG Energy, Inc. $NRG Receives $21.13 Average ...   \n",
            "9091537  Reviewing Arch Therapeutics $ARTH and Globus M...   \n",
            "9091538  $JD Beginning stage of a breakout. Strong buy ...   \n",
            "\n",
            "                    user_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
            "0        859451814940336128                      0                    0   \n",
            "1                  44060322                      0                    0   \n",
            "2        713570637306986496                      0                    0   \n",
            "3        823239593151655936                      0                    0   \n",
            "4                  44367489                      0                    0   \n",
            "...                     ...                    ...                  ...   \n",
            "9091534          2920258887                      0                    0   \n",
            "9091535          2920258887                      0                    0   \n",
            "9091536          2920258887                      0                    0   \n",
            "9091537          2920258887                      0                    0   \n",
            "9091538  840771557601423360                      0                    0   \n",
            "\n",
            "         retweeted_status_id  retweeted_user_id lang  \\\n",
            "0         865323140531896320         3005609114   en   \n",
            "1                          0                  0   en   \n",
            "2                          0                  0   en   \n",
            "3                          0                  0   en   \n",
            "4                          0                  0   en   \n",
            "...                      ...                ...  ...   \n",
            "9091534                    0                  0   pt   \n",
            "9091535                    0                  0   da   \n",
            "9091536                    0                  0   en   \n",
            "9091537                    0                  0   en   \n",
            "9091538                    0                  0   en   \n",
            "\n",
            "                                                    source  \\\n",
            "0        <a href=\"http://twitter.com/download/iphone\" r...   \n",
            "1        <a href=\"https://about.twitter.com/products/tw...   \n",
            "2        <a href=\"https://u.9999yea.rs/bots/\" rel=\"nofo...   \n",
            "3        <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
            "4        <a href=\"https://about.twitter.com/products/tw...   \n",
            "...                                                    ...   \n",
            "9091534  <a href=\"https://ifttt.com\" rel=\"nofollow\">IFT...   \n",
            "9091535  <a href=\"https://ifttt.com\" rel=\"nofollow\">IFT...   \n",
            "9091536  <a href=\"https://ifttt.com\" rel=\"nofollow\">IFT...   \n",
            "9091537  <a href=\"https://ifttt.com\" rel=\"nofollow\">IFT...   \n",
            "9091538  <a href=\"http://www.twitter.com\" rel=\"nofollow...   \n",
            "\n",
            "                             created_at  \n",
            "0        Thu May 18 22:00:00 +0000 2017  \n",
            "1        Thu May 18 22:00:01 +0000 2017  \n",
            "2        Thu May 18 22:00:02 +0000 2017  \n",
            "3        Thu May 18 22:00:02 +0000 2017  \n",
            "4        Thu May 18 22:00:02 +0000 2017  \n",
            "...                                 ...  \n",
            "9091534  Tue Sep 12 21:59:53 +0000 2017  \n",
            "9091535  Tue Sep 12 21:59:54 +0000 2017  \n",
            "9091536  Tue Sep 12 21:59:55 +0000 2017  \n",
            "9091537  Tue Sep 12 21:59:56 +0000 2017  \n",
            "9091538  Tue Sep 12 21:59:56 +0000 2017  \n",
            "\n",
            "[9091539 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "print(tweets_df)"
      ],
      "id": "C_O2ktUaOxvP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXmfl8B9P-O_",
        "outputId": "2d737e23-4adc-499a-e8c4-cbfc6dd46e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://t.co/0iuk9iq2il // Video Analysis $AMAT // $AMAT #trading #investing #stocks https://t.co/10dHVbxARc\n"
          ]
        }
      ],
      "source": [
        "print(tweets_df['text'][12])"
      ],
      "id": "nXmfl8B9P-O_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyt8dVSFKndd"
      },
      "source": [
        "• Statistics on distributions of 5 individual stocks over time. Choose the individual stocks to perform reflect different sectors of the economy."
      ],
      "id": "hyt8dVSFKndd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikqppW0UKlQo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming tweets_df contains the relevant information about tweets\n",
        "\n",
        "# Choose five individual stocks representing different sectors\n",
        "selected_stocks = ['AAPL', 'GOOGL', 'AMZN', 'MSFT', 'TSLA']\n",
        "\n",
        "# Filter the dataset for the selected stocks\n",
        "selected_stocks_df = tweets_df[tweets_df['ticker'].isin(selected_stocks)]\n",
        "\n",
        "# Convert the timestamp column to datetime format\n",
        "selected_stocks_df['created_at'] = pd.to_datetime(selected_stocks_df['created_at'])\n",
        "\n",
        "# Set the timestamp column as the index\n",
        "selected_stocks_df.set_index('created_at', inplace=True)\n",
        "\n",
        "# Plot the distribution of tweets over time for each selected stock\n",
        "plt.figure(figsize=(15, 8))\n",
        "for stock in selected_stocks:\n",
        "    stock_data = selected_stocks_df[selected_stocks_df['ticker'] == stock]\n",
        "    stock_data.resample('M').size().plot(label=stock, linewidth=2)\n",
        "\n",
        "plt.title('Distribution of Tweets Over Time for Selected Stocks')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Tweets')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "id": "ikqppW0UKlQo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac2ddc5a-b057-417f-9cf0-ed8a788b362e"
      },
      "source": [
        "\n",
        "  <style>\n",
        "    body {\n",
        "      font-family: sans-serif;\n",
        "      margin: 20px;\n",
        "    }\n",
        "\n",
        "    h1, h2 {\n",
        "      color: #333;\n",
        "    }\n",
        "\n",
        "    p {\n",
        "      color: #666;\n",
        "    }\n",
        "\n",
        "    .code {\n",
        "      font-family: 'Courier New', monospace;\n",
        "      background-color: #f4f4f4;\n",
        "      padding: 10px;\n",
        "      border-radius: 5px;\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h1>Part 2. Sentiment Analysis</h1>\n",
        "\n",
        "<h2>Loading and Preprocessing the Dataset</h2>\n",
        "<p>Let's start by loading and preprocessing the dataset. initial steps to prepare the data for exploratory analysis.</p>\n",
        "\n",
        "\n"
      ],
      "id": "ac2ddc5a-b057-417f-9cf0-ed8a788b362e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f752d02a-52bd-4f6a-8e12-1215c0217308"
      },
      "source": [
        "* Libraries installation and initialization"
      ],
      "id": "f752d02a-52bd-4f6a-8e12-1215c0217308"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92c220e7-9a99-4f39-a1f0-c436d178c2d9"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip"
      ],
      "id": "92c220e7-9a99-4f39-a1f0-c436d178c2d9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35202b8b-ada6-4ff8-8860-ba3db04ade10"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install tqdm pandas matplotlib tensorflow-data-validation"
      ],
      "id": "35202b8b-ada6-4ff8-8860-ba3db04ade10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5489226-5a24-485c-8ed9-266c09b968ba"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tensorflow/data-validation\n",
        "!cd data-validation"
      ],
      "id": "c5489226-5a24-485c-8ed9-266c09b968ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3abb699c-c902-4fde-8e73-423cb21ccdf4"
      },
      "outputs": [],
      "source": [
        "!python3 setup.py bdist_wheel"
      ],
      "id": "3abb699c-c902-4fde-8e73-423cb21ccdf4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "918dfa0a-a8e6-4488-9490-c8405fd54dc8"
      },
      "outputs": [],
      "source": [
        "pip install dist/*.whl"
      ],
      "id": "918dfa0a-a8e6-4488-9490-c8405fd54dc8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b19bfa68-ffb2-49ed-a5b8-ee37b8327c58"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow_data_validation as tfdv"
      ],
      "id": "b19bfa68-ffb2-49ed-a5b8-ee37b8327c58"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99be9a09-583b-40bc-9cb4-72d343eafa70"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_path = 'training.1600000.processed.noemoticon.csv'\n",
        "# Load the dataset with tqdm progress bar\n",
        "tqdm.pandas()\n",
        "df = pd.read_csv(file_path, header=None, encoding='latin1')\n",
        "\n"
      ],
      "id": "99be9a09-583b-40bc-9cb4-72d343eafa70"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51514f03-d6fb-40c9-a9c8-a324c5083bb4"
      },
      "outputs": [],
      "source": [
        "# Display basic information about the dataset\n",
        "print(\"Head of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nInformation about the DataFrame:\")\n",
        "print(df.info())\n",
        "\n"
      ],
      "id": "51514f03-d6fb-40c9-a9c8-a324c5083bb4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f6a1e6a-1af5-4516-97b0-272af01e82b2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot sentiment distribution in a pie plot\n",
        "sentiment_counts = df[0].value_counts()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90, colors=['red', 'gray', 'green'])\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.show()\n"
      ],
      "id": "6f6a1e6a-1af5-4516-97b0-272af01e82b2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd3749f9-915a-4b88-a54e-fb6b6964911d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot tweet length distribution with higher bins\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.hist(df[5].apply(len), bins=50, color='skyblue')\n",
        "plt.title('Tweet Length Distribution')\n",
        "plt.xlabel('Tweet Length')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "id": "cd3749f9-915a-4b88-a54e-fb6b6964911d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83020519-12e3-48cd-8733-fac835d2543c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "# If not, replace df with your actual DataFrame\n",
        "\n",
        "# Filter negative and positive sentiment tweets\n",
        "negative_tweets = df[df[0] == 0]\n",
        "positive_tweets = df[df[0] == 4]\n",
        "\n",
        "# Convert date columns to datetime\n",
        "negative_tweets[2] = pd.to_datetime(negative_tweets[2].astype(str).str.replace('PDT', ''), errors='coerce').dt.tz_localize('UTC')\n",
        "positive_tweets[2] = pd.to_datetime(positive_tweets[2].astype(str).str.replace('PDT', ''), errors='coerce').dt.tz_localize('UTC')\n",
        "\n",
        "# Plot negative sentiment tweets over time\n",
        "plt.figure(figsize=(12, 6))\n",
        "negative_tweets.groupby(negative_tweets[2].dt.date).size().plot(marker='o', linestyle='-', color='red', label='Negative Sentiment')\n",
        "positive_tweets.groupby(positive_tweets[2].dt.date).size().plot(marker='o', linestyle='-', color='green', label='Positive Sentiment')\n",
        "plt.title(' Sentiment Tweets Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "id": "83020519-12e3-48cd-8733-fac835d2543c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49130111-54d5-4828-8e9b-e51a257de00a"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_unique_users = df[4].nunique()\n",
        "print(f\"Number of Unique User IDs: {num_unique_users}\")"
      ],
      "id": "49130111-54d5-4828-8e9b-e51a257de00a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b451549-b6f6-49e4-b8e9-113cbe41abaf"
      },
      "source": [
        "### Information about the DataFrame:\n",
        "\n",
        "The dataset contains **1,600,000** entries with **6** columns. Here's an explanation of each column:\n",
        "\n",
        "1. **Column 0 (0):**\n",
        "   - **Data Type:** int64\n",
        "   - **Non-Null Count:** 1,600,000\n",
        "   - This column appears to be of numeric type (`int64`) and has no missing values. It might represent some numerical information.\n",
        "\n",
        "2. **Column 1 (1):**\n",
        "   - **Data Type:** int64\n",
        "   - **Non-Null Count:** 1,600,000\n",
        "   - Similar to Column 0, this column is also of numeric type (`int64`) with no missing values.\n",
        "\n",
        "3. **Column 2 (2):**\n",
        "   - **Data Type:** object\n",
        "   - **Non-Null Count:** 1,600,000\n",
        "   - This column is of object type, typically indicating text or categorical data.\n",
        "\n",
        "4. **Column 3 (3):**\n",
        "   - **Data Type:** object\n",
        "   - **Non-Null Count:** 1,600,000\n",
        "   - Another object-type column, likely containing textual or categorical information.\n",
        "\n",
        "5. **Column 4 (4):**\n",
        "   - **Data Type:** object\n",
        "   - **Non-Null Count:** 1,600,000\n",
        "   - Similar to Columns 2 and 3, this column is of object type.\n",
        "\n",
        "6. **Column 5 (5):**\n",
        "   - **Data Type:** object\n",
        "   - **Non-Null Count:** 1,600,000\n",
        "   - The last column is also of object type, indicating text or categorical data.\n",
        "\n",
        "The overall memory usage for the DataFrame is **73.2+ MB**.\n",
        "\n",
        "This information provides an overview of the data types, non-null counts, and memory usage for each column in the DataFrame.\n"
      ],
      "id": "5b451549-b6f6-49e4-b8e9-113cbe41abaf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b04f1fc-a341-4684-97ce-4d16d1318672"
      },
      "source": [
        "<style>\n",
        "  table {\n",
        "    font-family: Arial, sans-serif;\n",
        "    border-collapse: collapse;\n",
        "    width: 100%;\n",
        "  }\n",
        "\n",
        "  th, td {\n",
        "    border: 1px solid #dddddd;\n",
        "    text-align: left;\n",
        "    padding: 8px;\n",
        "  }\n",
        "\n",
        "  th {\n",
        "    background-color: #f2f2f2;\n",
        "  }\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h2>References</h2>\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Reference</th>\n",
        "    <th>Link</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Reference 1</td>\n",
        "    <td><a href=\"https://arxiv.org/pdf/1804.04406.pdf\" target=\"_blank\">https://arxiv.org/pdf/1804.04406.pdf</a></td>\n",
        "  </tr>\n",
        "  <!-- Add more rows for additional references if needed -->\n",
        "</table>"
      ],
      "id": "6b04f1fc-a341-4684-97ce-4d16d1318672"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "961bf7f8-d0ee-4e55-9394-b1fc5aa77414"
      },
      "outputs": [],
      "source": [],
      "id": "961bf7f8-d0ee-4e55-9394-b1fc5aa77414"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}